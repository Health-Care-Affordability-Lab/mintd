#!/usr/bin/env python3
"""Generate Frictionless Table Schema for {{ project_name }}.

This script generates a JSON schema file describing the structure of data files
in data/final/. The output follows the Frictionless Table Schema specification:
https://specs.frictionlessdata.io/table-schema/

For Stata .dta files, variable labels and value labels are extracted and mapped
to Frictionless 'title' and 'categories' fields respectively.

DO NOT MODIFY - This file is managed by mintd.
"""

import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# Check for required dependencies
try:
    import pandas as pd
except ImportError:
    print("Error: pandas is required for schema generation.", file=sys.stderr)
    print("Install with: pip install pandas", file=sys.stderr)
    sys.exit(1)

# Frictionless Table Schema URL
FRICTIONLESS_SCHEMA_URL = "https://specs.frictionlessdata.io/schemas/table-schema.json"

# Supported file extensions
SUPPORTED_EXTENSIONS = {".csv", ".dta", ".xlsx", ".xls", ".json"}

# Default missing values (includes Stata's ".")
DEFAULT_MISSING_VALUES = ["", "NA", "."]


def extract_stata_metadata(file_path: Path) -> Dict[str, Dict[str, Any]]:
    """Extract variable labels and value labels from a Stata .dta file."""
    metadata: Dict[str, Dict[str, Any]] = {}

    with pd.io.stata.StataReader(file_path) as reader:
        variable_labels = reader.variable_labels()
        value_labels = reader.value_labels()
    columns = list(variable_labels.keys())

    for col in columns:
        var_label = variable_labels.get(col)
        col_meta: Dict[str, Any] = {"label": var_label if var_label else None}

        if col in value_labels:
            col_meta["categories"] = [
                {"value": k, "label": v} for k, v in value_labels[col].items()
            ]

        metadata[col] = col_meta

    return metadata


def read_dataframe(file_path: Path) -> pd.DataFrame:
    """Read a data file into a pandas DataFrame."""
    ext = file_path.suffix.lower()

    if ext == ".csv":
        return pd.read_csv(file_path)
    elif ext == ".dta":
        return pd.read_stata(file_path)
    elif ext in {".xlsx", ".xls"}:
        return pd.read_excel(file_path)
    elif ext == ".json":
        return pd.read_json(file_path)
    else:
        raise ValueError(f"Unsupported file format: {ext}")


def infer_field_type(series: pd.Series) -> str:
    """Infer Frictionless field type from a pandas Series."""
    dtype = str(series.dtype).lower()

    # Handle non-string types directly
    if dtype not in ("object", "str", "string"):
        if dtype.startswith("int"):
            return "integer"
        elif dtype.startswith("float"):
            return "number"
        elif dtype.startswith("bool"):
            return "boolean"
        elif dtype.startswith("datetime"):
            return "datetime"
        elif "date" in dtype:
            return "date"
        elif dtype == "category":
            return "string"
        else:
            return "string"

    # For string/object columns, try to infer more specific types
    non_null = series.dropna()
    if len(non_null) == 0:
        return "string"

    sample = non_null.head(100)

    # Try parsing as date (YYYY-MM-DD format)
    try:
        pd.to_datetime(sample, format="%Y-%m-%d", errors="raise")
        return "date"
    except (ValueError, TypeError):
        pass

    # Try parsing as datetime
    try:
        pd.to_datetime(sample, format="ISO8601", errors="raise")
        return "datetime"
    except (ValueError, TypeError):
        pass

    return "string"


def generate_table_schema(
    file_path: Path,
    stata_metadata: Optional[Dict[str, Dict[str, Any]]] = None,
) -> Dict[str, Any]:
    """Generate Frictionless Table Schema for a single data file."""
    ext = file_path.suffix.lower()

    # Extract Stata metadata if applicable
    if ext == ".dta" and stata_metadata is None:
        stata_metadata = extract_stata_metadata(file_path)

    df = read_dataframe(file_path)

    fields: List[Dict[str, Any]] = []
    for col in df.columns:
        field: Dict[str, Any] = {
            "name": col,
            "type": infer_field_type(df[col]),
        }

        # Add Stata metadata if available
        if stata_metadata and col in stata_metadata:
            col_meta = stata_metadata[col]
            if col_meta.get("label"):
                field["title"] = col_meta["label"]
            if "categories" in col_meta:
                field["categories"] = col_meta["categories"]

        fields.append(field)

    return {
        "$schema": FRICTIONLESS_SCHEMA_URL,
        "fields": fields,
        "missingValues": DEFAULT_MISSING_VALUES,
    }


def find_data_files(directory: Path) -> List[Path]:
    """Find all supported data files in a directory."""
    data_files = []
    for ext in SUPPORTED_EXTENSIONS:
        data_files.extend(directory.glob(f"**/*{ext}"))
    return sorted(data_files)


def main():
    """Generate schema from final data files."""
    # This script runs from schemas/ directory
    final_dir = Path("../data/final")
    schema_dir = Path("v1")
    schema_file = schema_dir / "schema.json"

    # Ensure output directory exists
    schema_dir.mkdir(parents=True, exist_ok=True)

    # Find all data files
    data_files = find_data_files(final_dir)

    # Build combined schema output
    combined: Dict[str, Any] = {
        "generated_at": datetime.now().isoformat(),
        "generator": "mintd",
        "schema_standard": "frictionless-table-schema",
        "files": [],
    }

    if not data_files:
        print("No data files found in ../data/final/")
    else:
        for data_file in data_files:
            try:
                df = read_dataframe(data_file)
                schema = generate_table_schema(data_file)

                file_entry = {
                    "filename": data_file.name,
                    "path": str(data_file.relative_to(final_dir)),
                    "observations": len(df),
                    "columns": len(df.columns),
                    "schema": schema,
                }
                combined["files"].append(file_entry)
                print(f"  Generated schema for: {data_file.name}")
            except Exception as e:
                print(f"  Warning: Could not generate schema for {data_file.name}: {e}")

    # Write schema
    with open(schema_file, "w") as f:
        json.dump(combined, f, indent=2, default=str)

    print(f"Schema saved to: {schema_file}")


if __name__ == "__main__":
    main()
