#' mintd utility functions for {{ project_name }}.
#'
#' This module provides common utilities used across all project scripts.
#' DO NOT MODIFY - This file is managed by mintd and will be overwritten.
#'
#' NOTE: Scripts are expected to run from the code/ directory.
#' Data paths should use "../data/" or the get_data_paths() function.

# =============================================================================
# PATH DEFINITIONS (relative to code/ where scripts run from)
# =============================================================================

DATA_DIR <- "../data"
RAW_DIR <- "../data/raw"
ANALYSIS_DIR <- "../data/analysis"

#' Get standard data directory paths
#'
#' @return Named list with paths: data, raw, analysis
#' @export
get_data_paths <- function() {
  list(
    data = DATA_DIR,
    raw = RAW_DIR,
    analysis = ANALYSIS_DIR
  )
}

#' Validate we're running from code/ directory and return project root
#'
#' This function checks if we're in the correct directory structure:
#' - Preferred: Running from code/ (project indicators in parent)
#' - Fallback: Running from project root (for backwards compatibility)
#'
#' @return Character string of project root directory
#' @export
setup_project_directory <- function() {
  current_dir <- getwd()

  # Look for project root indicators
  root_indicators <- c("metadata.json", ".git")

  # Check if we're in code/ (project indicators in parent directory)
  is_in_src <- FALSE
  for (indicator in root_indicators) {
    if (file.exists(file.path("..", indicator))) {
      is_in_src <- TRUE
      break
    }
  }

  if (is_in_src) {
    # We're in code/, paths are already correct
    return(normalizePath(file.path(current_dir, "..")))
  }

  # Check if we're in project root (backwards compatibility)
  root_found <- FALSE
  for (indicator in root_indicators) {
    if (file.exists(indicator)) {
      root_found <- TRUE
      break
    }
  }

  if (root_found) {
    # Update paths for project-root execution
    DATA_DIR <<- "data"
    RAW_DIR <<- "data/raw"
    ANALYSIS_DIR <<- "data/analysis"
    return(normalizePath(current_dir))
  }

  # Not in a valid location
  stop(
    paste0(
      "Not running from expected directory.\n",
      "Scripts should be run from code/ directory.\n",
      "Current directory: ", current_dir, "\n",
      "Please cd to the project's code/ directory and try again."
    )
  )
}

#' Generate data schema from file
#'
#' @param data_path Path to data file
#' @param output_path Optional path to save schema JSON
#' @return List containing schema information
#' @export
generate_data_schema <- function(data_path, output_path = NULL) {
  tryCatch({
    # Read data based on file extension
    ext <- tolower(tools::file_ext(data_path))

    if (ext == "csv") {
      df <- read.csv(data_path, stringsAsFactors = FALSE)
    } else if (ext == "json") {
      df <- jsonlite::fromJSON(data_path)
      if (!is.data.frame(df)) {
        stop("JSON file does not contain a data frame")
      }
    } else if (ext %in% c("xlsx", "xls")) {
      df <- readxl::read_excel(data_path)
    } else if (ext == "rds") {
      df <- readRDS(data_path)
    } else if (ext == "dta") {
      df <- haven::read_dta(data_path)
    } else {
      stop("Unsupported file format: ", ext)
    }

    # Generate schema
    schema <- list(
      filename = basename(data_path),
      filepath = normalizePath(data_path),
      observations = nrow(df),
      columns = ncol(df),
      variables = list()
    )

    for (col_name in colnames(df)) {
      col_data <- df[[col_name]]

      # Basic type detection
      if (is.integer(col_data)) {
        var_type <- "integer"
      } else if (is.numeric(col_data)) {
        var_type <- "numeric"
      } else if (is.character(col_data)) {
        var_type <- "string"
      } else if (is.logical(col_data)) {
        var_type <- "boolean"
      } else if (inherits(col_data, "Date")) {
        var_type <- "date"
      } else if (inherits(col_data, "POSIXct")) {
        var_type <- "datetime"
      } else {
        var_type <- typeof(col_data)
      }

      # Generate basic label from column name
      label <- tools::toTitleCase(gsub("[._-]", " ", col_name))

      variable_info <- list(
        name = col_name,
        type = var_type,
        label = label,
        missing_count = sum(is.na(col_data)),
        unique_values = if (is.character(col_data)) length(unique(col_data)) else NULL
      )

      # Add numeric statistics for numeric columns
      if (var_type %in% c("integer", "numeric")) {
        variable_info <- c(variable_info, list(
          min = if (all(is.na(col_data))) NULL else min(col_data, na.rm = TRUE),
          max = if (all(is.na(col_data))) NULL else max(col_data, na.rm = TRUE),
          mean = if (all(is.na(col_data))) NULL else mean(col_data, na.rm = TRUE),
          sd = if (all(is.na(col_data))) NULL else sd(col_data, na.rm = TRUE)
        ))
      }

      schema$variables <- c(schema$variables, list(variable_info))
    }

    # Save schema if output path provided
    if (!is.null(output_path)) {
      dir.create(dirname(output_path), recursive = TRUE, showWarnings = FALSE)
      jsonlite::write_json(schema, output_path, pretty = TRUE, auto_unbox = TRUE)
    }

    return(schema)

  }, error = function(e) {
    stop("Failed to generate schema for ", data_path, ": ", e$message)
  })
}

#' Find data files in a directory
#'
#' @param directory Directory to search
#' @param extensions File extensions to look for
#' @return Character vector of data file paths
#' @export
find_data_files <- function(directory, extensions = NULL) {
  if (is.null(extensions)) {
    extensions <- c("csv", "json", "xlsx", "xls", "dta", "rds", "sav")
  }

  files <- character(0)
  for (ext in extensions) {
    pattern <- paste0("*.", ext)
    found <- list.files(directory, pattern = pattern, recursive = TRUE, full.names = TRUE)
    files <- c(files, found)
  }

  return(sort(files))
}
