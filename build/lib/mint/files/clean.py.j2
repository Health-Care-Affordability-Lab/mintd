"""Data cleaning script for {{ project_name }}.

NOTE: This script runs from the src/ directory. Data paths use ../data/
"""

import sys
from pathlib import Path
import pandas as pd

# Import mint utilities (located in same src/ directory)
from _mint_utils import (
    setup_project_directory,
    ParameterAwareLogger,
    RAW_DIR,
    INTERMEDIATE_DIR,
    FINAL_DIR,
    get_data_paths
)


def main():
    """Main cleaning workflow."""
    # Initialize logging (validates directory and creates log file)
    logger = ParameterAwareLogger("clean")
    logger.log("Starting data cleaning for {{ project_name }}...")

    # Get data paths and ensure directories exist
    paths = get_data_paths()
    for name, path in paths.items():
        if name != 'logs':  # logs already created by logger
            path.mkdir(parents=True, exist_ok=True)

    logger.log(f"Raw data directory: {RAW_DIR}")
    logger.log(f"Intermediate data directory: {INTERMEDIATE_DIR}")
    logger.log(f"Final data directory: {FINAL_DIR}")

    # TODO: Implement data cleaning logic
    # - Load raw data from RAW_DIR/
    # - Handle missing values, data types, outliers
    # - Standardize formats and encodings
    # - Save cleaned data to INTERMEDIATE_DIR/

    # Example:
    # # Load raw data
    # raw_files = list(RAW_DIR.glob("*.csv"))
    # for raw_file in raw_files:
    #     df = pd.read_csv(raw_file)
    #
    #     # Basic cleaning
    #     df = df.dropna()  # Remove missing values
    #     df.columns = df.columns.str.lower().str.replace(' ', '_')
    #
    #     # Save cleaned data
    #     intermediate_file = INTERMEDIATE_DIR / f"clean_{raw_file.name}"
    #     df.to_csv(intermediate_file, index=False)
    #     logger.log(f"Cleaned {len(df)} rows, saved to {intermediate_file}")

    logger.log("Data cleaning completed successfully.")
    logger.close()


if __name__ == "__main__":
    main()